{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f722a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ML Pipeline with Feature Engineering and Model Save\n",
    "# ============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "\n",
    "# ----------------------------\n",
    "# 1️⃣ Original DataFrame (from image)\n",
    "# ----------------------------\n",
    "data = {\n",
    "    'age': [64, 51, 67, 60, 40],\n",
    "    'weight': [59.8, 100.6, 114.5, 117.8, 70.0],\n",
    "    'height': [1.63, 1.68, 1.74, 1.66, 1.59],\n",
    "    'income_lpa': [3.87, 11.99, 0.61, 50.0, 28.16664],\n",
    "    'smoker': [False, True, True, True, True],\n",
    "    'city': ['Mumbai', 'Bangalore', 'Mumbai', 'Lucknow', 'Bangalore'],\n",
    "    'occupation': ['retired', 'unemployed', 'retired', 'business_owner', 'government_job'],\n",
    "    'insurance_premium_category': ['Medium', 'High', 'High', 'High', 'Low']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "n_samples = 5000\n",
    "\n",
    "# Randomly sample with replacement\n",
    "df_expanded = df.sample(n=n_samples, replace=True, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Add some small noise to numeric columns for realism\n",
    "# -----------------------------\n",
    "np.random.seed(42)\n",
    "df_expanded['age'] += np.random.randint(-2, 3, size=n_samples)      # +/- 2 years\n",
    "df_expanded['weight'] += np.random.uniform(-3, 3, size=n_samples)   # +/- 3 kg\n",
    "df_expanded['height'] += np.random.uniform(-0.05, 0.05, size=n_samples) # +/- 5 cm\n",
    "df_expanded['income_lpa'] += np.random.uniform(-2, 2, size=n_samples)  # +/- 2 LPA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1bbcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2️⃣ Feature Engineering\n",
    "# ----------------------------\n",
    "\n",
    "# BMI = weight / (height^2)\n",
    "df['bmi'] = df['weight'] / (df['height'] ** 2)\n",
    "\n",
    "# Age group\n",
    "def age_group(age):\n",
    "    if age < 18 : \n",
    "        return 'child'\n",
    "    elif age < 25:\n",
    "        return 'young'\n",
    "    elif age < 35:\n",
    "        return 'middle_aged'\n",
    "    else : \n",
    "        return 'senior'\n",
    "\n",
    "df['age_group'] = df['age'].apply(age_group)\n",
    "\n",
    "# Lifestyle risk based on BMI + smoker\n",
    "def lifestyle_risk(row):\n",
    "    if row['smoker'] and row['bmi'] > 30:\n",
    "        return 'high'\n",
    "    elif row['smoker'] or row['bmi'] > 27:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'low'\n",
    "df['lifestyle_risk'] = df.apply(lifestyle_risk, axis=1)\n",
    "\n",
    "# City tier mapping\n",
    "city_tier_map = {'Mumbai':2, 'Bangalore':2, 'Lucknow':1}\n",
    "df['city_tier'] = df['city'].map(city_tier_map)\n",
    "\n",
    "# Select features for ML\n",
    "X = df[['bmi', 'age_group', 'lifestyle_risk', 'city_tier', 'income_lpa', 'occupation']]\n",
    "y = df['insurance_premium_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5bbc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3️⃣ Preprocessing\n",
    "# ----------------------------\n",
    "numeric_features = ['bmi', 'income_lpa', 'city_tier']\n",
    "categorical_features = ['age_group', 'lifestyle_risk', 'occupation']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first', sparse_output=False,handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c32d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "Model saved successfully as 'model.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Asadullah Core\\Apps\\AS\\envs\\fastapi_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 4️⃣ ML Pipeline\n",
    "# ----------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# 5️⃣ Train/Test Split\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# 6️⃣ Train Model\n",
    "# ----------------------------\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# 7️⃣ Evaluate Model\n",
    "# ----------------------------\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ----------------------------\n",
    "# 8️⃣ Save Model using pickle\n",
    "# ----------------------------\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline, file)\n",
    "\n",
    "print(\"Model saved successfully as 'model.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
